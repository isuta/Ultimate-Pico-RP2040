# テストガイド

このドキュメントでは、プロジェクトのテストスイートについて説明します。

---

## 📚 テストの概要

このプロジェクトには、**PC上で実行可能な単体テスト**が含まれています。  
Raspberry Pi Picoに転送する前に、ロジックの正当性を検証できるため、開発速度が大幅に向上します。

### テストの目的

1. **バグの早期発見**: コード修正後、すぐに問題を検出
2. **リグレッション防止**: 既存機能が壊れていないことを確認
3. **ドキュメント化**: テストコードが仕様書の役割を果たす
4. **安心してリファクタリング**: テストがあれば大胆に改善可能

---

## 🧪 テストスイート一覧

### 1. command_parser.py のテスト

**ファイル**: `tests/test_command_parser.py`  
**テストケース数**: 36件  
**実行時間**: 約1秒

#### テスト内容

| テストグループ | 検証項目 | テストケース数 |
|---------------|---------|--------------|
| **get_param()** | 辞書からパラメータを安全に取得 | 5件 |
| **validate_range()** | 数値が範囲内かチェック、範囲外はクランプ | 7件 |
| **validate_positive()** | 正数かどうかをチェック | 5件 |
| **validate_color()** | RGB値（0-255）の妥当性チェック | 11件 |
| **parse_command_type()** | コマンド形式（辞書/リスト）の解析 | 8件 |

#### 具体的な検証内容

##### get_param() - パラメータ取得の安全性
```python
# 正常ケース
{"led": "on", "brightness": 100} から "brightness" を取得 → 100

# エラーケース
存在しないキー → デフォルト値を返す（None or 指定値）
空辞書 → デフォルト値を返す
```

##### validate_range() - 範囲チェックとクランプ
```python
# 正常ケース
validate_range(50, 0, 100) → 50（範囲内）

# クランプ処理
validate_range(-10, 0, 100) → 0（下限未満をクランプ）
validate_range(150, 0, 100) → 100（上限超過をクランプ）
```

##### validate_color() - RGB値の検証
```python
# 正常ケース
[255, 128, 0] → (255, 128, 0)  # オレンジ色
(0, 0, 0) → (0, 0, 0)          # 黒

# エラーケース
[255, 128] → None              # 要素数不足
[256, 128, 0] → None           # R値が範囲外（0-255）
"red" → None                   # 文字列は不正
```

##### parse_command_type() - コマンド形式の柔軟な解析
```python
# 辞書形式（typeキー指定）
{"type": "led", "command": "on"} → "led"

# 辞書形式（typeキーなし）
{"led_on": {"brightness": 100}} → "led_on"

# リスト形式
["delay", 1000] → "delay"
```

#### 実行方法
```bash
python tests/test_command_parser.py
```

#### 実行結果例
```
============================================================
Command Parser テストスイート
============================================================

=== get_param() テスト ===
✓ 存在するキーの取得
✓ 数値パラメータの取得
✓ 存在しないキー（デフォルトNone）
✓ 存在しないキー（デフォルト50）
✓ 空辞書でデフォルト値

=== validate_range() テスト ===
✓ 範囲内の値（中央）
✓ 範囲内の値（最小）
✓ 範囲内の値（最大）
[Warning] value -10 out of range (0～100), clamping.
✓ 範囲外（下限未満→クランプ）
...

============================================================
テスト結果: 36 合格 / 0 失敗
============================================================
✅ すべてのテストが合格しました！
```

---

### 2. logger.py のテスト

**ファイル**: `tests/test_logger.py`  
**テストケース数**: 20件  
**実行時間**: 約1秒

#### テスト内容

ログレベル（LOG_LEVEL）に応じた出力フィルタリングが正しく動作するかを検証します。

| LOG_LEVEL | 出力されるメッセージ | 用途 |
|-----------|---------------------|------|
| **0** | ERROR のみ | 本番環境（最小限のログ） |
| **1** | ERROR + WARNING | 本番環境（警告も記録） |
| **2** | ERROR + WARNING + INFO | デフォルト（開発・運用） |
| **3** | すべて（DEBUG含む） | 詳細なデバッグ |

#### 具体的な検証内容

##### LOG_LEVEL=0（ERRORのみ）
```python
log_error("エラー発生")    # ✓ 表示される
log_warning("警告")        # ✗ 非表示
log_info("情報")           # ✗ 非表示
log_debug("デバッグ情報")  # ✗ 非表示
```

##### LOG_LEVEL=2（デフォルト）
```python
log_error("エラー発生")    # ✓ 表示される
log_warning("警告")        # ✓ 表示される
log_info("情報")           # ✓ 表示される
log_debug("デバッグ情報")  # ✗ 非表示
```

##### LOG_LEVEL=3（すべて表示）
```python
log_error("エラー発生")    # ✓ 表示される
log_warning("警告")        # ✓ 表示される
log_info("情報")           # ✓ 表示される
log_debug("デバッグ情報")  # ✓ 表示される
```

##### LOG_LEVEL未定義時
```python
# config.py に LOG_LEVEL が無い場合
# → デフォルト値 2 (INFO) が使われる
log_info("情報")  # ✓ 表示される
log_debug("デバッグ") # ✗ 非表示
```

#### 実行方法
```bash
python tests/test_logger.py
```

#### 実行結果例
```
============================================================
Logger テストスイート
============================================================

=== LOG_LEVEL=0（ERRORのみ）===
✓ ERROR（レベル0）は表示
✓ WARNING（レベル1）は非表示
✓ INFO（レベル2）は非表示
✓ DEBUG（レベル3）は非表示

=== LOG_LEVEL=2（ERROR+WARNING+INFO）- デフォルト ===
✓ ERROR（レベル0）は表示
✓ WARNING（レベル1）は表示
✓ INFO（レベル2）は表示
✓ DEBUG（レベル3）は非表示
...

============================================================
テスト結果: 20 合格 / 0 失敗
============================================================
✅ すべてのテストが合格しました！
```

---

### 3. scenarios.json のバリデーション

**ファイル**: `tests/test_scenarios_validator.py`  
**チェック項目**: 104件  
**実行時間**: 約1秒

#### テスト内容

scenarios.json ファイルの形式と内容を包括的に検証します。

| カテゴリ | 検証内容 | チェック数 |
|---------|---------|-----------|
| **JSON形式** | ファイル読み込み、パース可能性 | 1件 |
| **データ構造** | トップレベルが辞書形式か | 2件 |
| **シナリオキー** | 数値キーの妥当性（負数チェック） | 58件 |
| **シナリオ内容** | コマンドリストの形式、コマンド数 | 58件 |
| **よくある問題** | delay=0、メモリ不足リスク等 | 動的 |

#### 具体的な検証内容

##### JSON形式の検証
```python
✓ JSONファイルが存在するか
✓ UTF-8エンコーディングで読み込めるか
✓ JSON形式として正しくパースできるか
✗ 構文エラー（カンマ忘れ、括弧の不一致等）
```

##### データ構造の検証
```json
// ✓ 正しい形式
{
  "1": [...],
  "2": [...],
  "test_scenario": [...]
}

// ✗ 不正な形式
[
  {"scenario": 1, "commands": [...]},
  ...
]
```

##### シナリオキーの検証
```python
# ✓ 正常なキー
"1", "2", "100" → 数値として解釈可能

# ⚠ 警告（動作には影響なし）
"test_servo_basic" → テスト用シナリオ（文字列キー）

# ✗ エラー
"-5" → 負数のシナリオ番号
```

##### シナリオ内容の検証
```json
// ✓ 正しいシナリオ
"1": [
  {"type": "led", "command": "on"},
  ["delay", 1000],
  {"type": "led", "command": "off"}
]

// ✗ 不正なシナリオ
"2": "invalid"  // リストではない
"3": []         // ⚠ 空のコマンドリスト
```

##### コマンド形式の検証
```json
// ✓ 正しいdelayコマンド
["delay", 1000]

// ✗ 不正なdelayコマンド
["delay"]           // 時間が指定されていない
["delay", "abc"]    // 時間が数値ではない
["delay", -100]     // 負数の時間
["delay", 0]        // ⚠ 意味のない0秒待機
```

##### メモリリスクの検出
```python
# ⚠ 警告: 非常に長いシナリオ
"scenario": [
  ...  // 100個以上のコマンド
]
# → メモリ不足の可能性を警告
```

#### 実行方法
```bash
python tests/test_scenarios_validator.py
```

#### 実行結果例
```
============================================================
Scenarios JSON バリデーター
対象ファイル: scenarios.json
============================================================

=== JSON形式の検証 ===
✓ JSONファイルの読み込み成功

=== データ構造の検証 ===
✓ トップレベルは辞書形式
✓ 58個のシナリオを検出

=== シナリオキーの検証 ===
✓ シナリオ 1: キー形式OK
✓ シナリオ 2: キー形式OK
⚠ シナリオキーが数値ではありません: test_servo_basic（テスト用シナリオ？）
...

=== シナリオ内容の検証 ===
✓ シナリオ 1: 7個のコマンド
✓ シナリオ 2: 9個のコマンド
...

=== よくある問題のチェック ===
（問題が検出された場合のみ表示）

============================================================
検証結果: 104 合格 / 0 失敗 / 15 警告
============================================================
✅ 致命的なエラーはありません
⚠️  15件の警告があります（動作には影響しません）
```

---

## 🚀 すべてのテストを実行

### 一括実行コマンド

```bash
# Windowsの場合
python tests/test_command_parser.py && python tests/test_logger.py && python tests/test_scenarios_validator.py

# macOS/Linuxの場合
python3 tests/test_command_parser.py && python3 tests/test_logger.py && python3 tests/test_scenarios_validator.py
```

### 期待される結果

```
============================================================
Command Parser テストスイート
============================================================
...
✅ すべてのテストが合格しました！

============================================================
Logger テストスイート
============================================================
...
✅ すべてのテストが合格しました！

============================================================
Scenarios JSON バリデーター
============================================================
...
✅ 致命的なエラーはありません
```

**総計: 160件のテスト・チェック項目**

---

## 🛠️ 開発ワークフロー

### 推奨される開発フロー

1. **コードを修正**
   ```bash
   vim command_parser.py
   ```

2. **テストを実行（Pico不要！）**
   ```bash
   python tests/test_command_parser.py
   ```

3. **テスト合格を確認**
   ```
   ✅ すべてのテストが合格しました！
   ```

4. **安心してコミット**
   ```bash
   git add .
   git commit -m "Fix: コマンド解析のバグ修正"
   ```

5. **Picoに転送して実機テスト**
   ```bash
   # この時点でロジックは検証済み
   # → ハードウェア動作のみ確認すればOK
   ```

### テスト失敗時の対応

```
============================================================
テスト結果: 35 合格 / 1 失敗
============================================================
❌ 1件のテストが失敗しました

✗ RGB値の検証
  Expected: (255, 128, 0)
  Actual: None
```

1. **失敗したテストを確認**
   - どの関数のどのケースが失敗したか
   - 期待値と実際の値の差分

2. **コードを修正**
   - テストが示す問題を修正

3. **再度テスト実行**
   - 修正が正しいか確認

4. **全テストが合格するまで繰り返す**

---

## 📝 テストの追加

新しいモジュールを追加した場合は、対応するテストも追加してください。

### テストファイルの作成手順

1. **tests/ ディレクトリにファイルを作成**
   ```bash
   touch tests/test_new_module.py
   ```

2. **基本構造を実装**
   ```python
   """
   Test suite for new_module.py
   """
   import sys
   from pathlib import Path
   
   sys.path.insert(0, str(Path(__file__).parent.parent))
   from new_module import function_to_test
   
   tests_passed = 0
   tests_failed = 0
   
   def assert_equal(actual, expected, test_name):
       global tests_passed, tests_failed
       if actual == expected:
           tests_passed += 1
           print(f"✓ {test_name}")
       else:
           tests_failed += 1
           print(f"✗ {test_name}")
           print(f"  Expected: {expected}")
           print(f"  Actual: {actual}")
   
   def test_basic_functionality():
       print("\n=== 基本機能のテスト ===")
       assert_equal(function_to_test(1, 2), 3, "1+2=3")
   
   if __name__ == "__main__":
       test_basic_functionality()
       print(f"\nテスト結果: {tests_passed} 合格 / {tests_failed} 失敗")
   ```

3. **テストを実行して確認**
   ```bash
   python tests/test_new_module.py
   ```

---

## ❓ FAQ

### Q1: テストはPico上でも実行できますか？

**A**: いいえ。これらのテストはPC上の標準Pythonで実行することを想定しています。  
MicroPython特有の機能（GPIO、PWM等）はテストできませんが、ロジック部分は十分検証できます。

### Q2: テストが失敗しても動作する可能性はありますか？

**A**: ありますが推奨しません。テストはコードの品質を保証するためのものです。  
失敗したテストを無視してPicoに転送すると、予期しない動作やバグの原因になります。

### Q3: scenarios.jsonの警告は修正すべきですか？

**A**: 必ずしも修正する必要はありません。警告は「動作に影響しないが、改善の余地がある」ことを示します。  
例：テスト用の文字列キー（`"test_servo_basic"`）は警告が出ますが、正常に動作します。

### Q4: 新しいテストケースを追加したいのですが？

**A**: 既存のテストファイル（`tests/test_*.py`）に追加するか、新しいテストファイルを作成してください。  
上記の「テストの追加」セクションを参考にしてください。

### Q5: テストの実行が遅いです

**A**: 各テストは1秒程度で完了します。3つすべて実行しても3秒程度です。  
それでも遅い場合は、特定のテストのみを実行してください：
```bash
python tests/test_command_parser.py  # 最も重要
```

---

## 🎯 テストのベストプラクティス

1. **コミット前にテストを実行**
   - すべてのテストが合格してからコミット

2. **コードとテストを同時に修正**
   - 機能追加時は対応するテストも追加

3. **テスト失敗は無視しない**
   - 失敗したらすぐに修正

4. **scenarios.json編集後は必ず検証**
   - バリデーターでエラーを早期発見

5. **READMEとテストを同期**
   - 機能変更時はドキュメントも更新

---

## 📚 関連ドキュメント

- [README.md](./README.md) - プロジェクト概要
- [DEVELOPMENT.md](./DEVELOPMENT.md) - 開発ガイドライン
- [SCENARIO_GUIDE.md](./SCENARIO_GUIDE.md) - シナリオ作成ガイド
- [ARCHITECTURE.md](./ARCHITECTURE.md) - システムアーキテクチャ
